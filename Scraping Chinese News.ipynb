{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from pathlib import Path\n",
    "\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \\\n",
    "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.149 Safari/537.36\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一带一路', '习近平', '李克强', '杨洁篪', '王沪宁', '栗战书', '张高丽', '张德江', '汪洋', '杨晶', '郭声琨', '王晨', '孟建柱', '王岐山', '陈雷', '刘奇葆', '刘鹤', '丁薛祥', '周文重', '高燕', '楼继伟', '高宝玉', '王毅', '何立峰', '孙春兰', '郝明金', '韩正', '肖捷', '夏宝龙', '彭丽媛', '李希', '崔世安']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.exceptions import RequestException, Timeout\n",
    "\n",
    "def get_search_result(word, page):\n",
    "    url = f\"http://search.people.com.cn/cnpeople/searchForChannel.do?totalPage=999\\\n",
    "&pageNum={page}&keyword={urllib.parse.quote(word.encode('GBK'))}&siteName=people&channelName=politics\"\n",
    "    try:\n",
    "        r = requests.get(url, timeout=7, headers=headers)\n",
    "    except (RequestException, Timeout) as e:\n",
    "        print(f'Error {e}')\n",
    "        return []\n",
    "    else:\n",
    "        print(r.status_code)  \n",
    "        if r.status_code == 200:\n",
    "            r.encoding = \"GBK\"\n",
    "            doc = soup(r.text, \"html5lib\")\n",
    "            res = [(x['href'], x.get_text()) for x in doc.select('.page2_list h2 a')]\n",
    "        else:\n",
    "            res = []\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date(x, fmt=r'.*(\\d{4})/(\\d{2})(\\d{2})'):\n",
    "    date = re.match(fmt, x)\n",
    "    return '-'.join(date.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(titles, cur_dir=None):\n",
    "    df = pd.DataFrame(titles, columns=['url', 'title'])\n",
    "    df = df.drop_duplicates()\n",
    "    df['date'] = pd.to_datetime(df['url'].apply(extract_date, fmt=r'.*(\\d{4}-\\d{2})/(\\d{2})'))\n",
    "    df[df.date.dt.year == 2019].sort_values(by='date', \n",
    "                        ascending=False).to_csv('%s.csv' % word, index=False)\n",
    "    return f'{word}.csv have been saved in {os.getcwd()}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка selenium.webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('--ignore-certificate-errors')\n",
    "options.add_argument('--incognito')\n",
    "options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(\"/usr/loca/bin/chromedriver\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Получаем результаты поиска постранично"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_result(word, page):\n",
    "    # по 50 резльтатов на странице за 2019 год\n",
    "    url = f'http://www.southcn.com/search/pc/advresult.html?keyword={word}\\\n",
    "&size=50&o=asc&category=南方网pc端&from=2019-01-01&to=2019-12-31&page={page}'\n",
    "    driver.get(url)\n",
    "    time.sleep(10) # задержка нужена, чтобы драйвер полностью получил содержимое страницы\n",
    "    return driver.page_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_titles(source):\n",
    "    doc = soup(source, \"html5lib\")\n",
    "    return [(x['href'], x.get_text()) for x in \n",
    "                    doc.select('.result-box .result-title a')], doc.select('.next')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Перебор списка запросов и получение результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53244f1283a8435987e497f8c6f6805f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "titles = []\n",
    "for word in words:\n",
    "    for num_page in tqdm.notebook.tqdm(range(1, 51)):\n",
    "        source = get_search_result(word, num_page)\n",
    "        time.sleep(10)\n",
    "        data, isnext = extract_titles(source)\n",
    "        titles += data\n",
    "        if isnext:\n",
    "            time.sleep(random.randint(1, 6))\n",
    "        else:\n",
    "            break\n",
    "    build_data(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Экспорт даных в Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_path = 'southcn.com.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {Path(file_name).stem: pd.read_csv(file_name) for file_name in csv_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(excel_path, engine='xlsxwriter') as writer:    \n",
    "    for name, df in df_dict.items():\n",
    "        df.to_excel(writer, name, index=False)   \n",
    "    writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
